{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "\n",
    "# Step 1: Download the dataset\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text  # This is the entire text data\n",
    "\n",
    "# Step 2: Prepare the dataset\n",
    "sequence_length = 20\n",
    "# Create a character mapping to integers\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# Encode the text into integers\n",
    "encoded_text = [char_to_int[ch] for ch in text]\n",
    "\n",
    "# Create sequences and targets\n",
    "sequences = []\n",
    "targets = []\n",
    "for i in range(0, len(encoded_text) - sequence_length):\n",
    "    seq = encoded_text[i:i+sequence_length]\n",
    "    target = encoded_text[i+sequence_length]\n",
    "    sequences.append(seq)\n",
    "    targets.append(target)\n",
    "\n",
    "# Convert lists to PyTorch tensors\n",
    "sequences = torch.tensor(sequences, dtype=torch.long)\n",
    "targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "# Step 3: Create a dataset class\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.sequences[index], self.targets[index]\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = CharDataset(sequences, targets)\n",
    "\n",
    "# Step 4: Create data loaders\n",
    "batch_size = 128\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# Now `train_loader` and `test_loader` are ready to be used in a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate GRU\n",
    "        out, _ = self.gru(x, h0)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model for sequence length 20...\n",
      "Epoch [1/10], Loss: 1.2143\n",
      "Epoch [2/10], Loss: 2.4413\n",
      "Epoch [3/10], Loss: 0.8708\n",
      "Epoch [4/10], Loss: 1.0888\n",
      "Epoch [5/10], Loss: 1.0486\n",
      "Epoch [6/10], Loss: 1.0847\n",
      "Epoch [7/10], Loss: 0.9794\n",
      "Epoch [8/10], Loss: 0.1467\n",
      "Epoch [9/10], Loss: 0.8002\n",
      "Epoch [10/10], Loss: 1.2631\n",
      "Training GRU model for sequence length 20...\n",
      "Epoch [1/10], Loss: 1.5718\n",
      "Epoch [2/10], Loss: 1.2375\n",
      "Epoch [3/10], Loss: 1.5314\n",
      "Epoch [4/10], Loss: 1.3200\n",
      "Epoch [5/10], Loss: 1.3027\n",
      "Epoch [6/10], Loss: 1.9289\n",
      "Epoch [7/10], Loss: 1.5252\n",
      "Epoch [8/10], Loss: 1.1134\n",
      "Epoch [9/10], Loss: 1.2726\n",
      "Epoch [10/10], Loss: 0.8503\n",
      "\n",
      "Comparison for Sequence Length 20:\n",
      "LSTM - Loss: 1.2631, Accuracy: 58.97%, Time: 255.64 seconds\n",
      "GRU  - Loss: 0.8503, Accuracy: 58.07%, Time: 246.63 seconds\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, test_loader, device, num_epochs=10, lr=0.001):\n",
    "    # Move model to the device (CPU or GPU)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        for sequences, targets in train_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Convert sequences to one-hot encoded vectors\n",
    "            one_hot_sequences = torch.zeros(sequences.size(0), sequences.size(1), input_size).to(device)\n",
    "            one_hot_sequences.scatter_(2, sequences.unsqueeze(2), 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(one_hot_sequences)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Calculate execution time\n",
    "    exec_time = time.time() - start_time\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for sequences, targets in test_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Convert sequences to one-hot encoded vectors\n",
    "            one_hot_sequences = torch.zeros(sequences.size(0), sequences.size(1), input_size).to(device)\n",
    "            one_hot_sequences.scatter_(2, sequences.unsqueeze(2), 1)\n",
    "\n",
    "            outputs = model(one_hot_sequences)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "    \n",
    "    return loss.item(), accuracy, exec_time, model\n",
    "\n",
    "# Train LSTM and GRU models for sequence length 20\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = len(chars)  # Number of unique characters\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "output_size = len(chars)\n",
    "num_epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "lstm_model_20 = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "gru_model_20 = GRUModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "print(\"Training LSTM model for sequence length 20...\")\n",
    "lstm_loss_20, lstm_acc_20, lstm_time_20, _ = train_model(lstm_model_20, train_loader, test_loader, device, num_epochs, lr)\n",
    "print(\"Training GRU model for sequence length 20...\")\n",
    "gru_loss_20, gru_acc_20, gru_time_20, _ = train_model(gru_model_20, train_loader, test_loader, device, num_epochs, lr)\n",
    "\n",
    "# Compare the results\n",
    "print(\"\\nComparison for Sequence Length 20:\")\n",
    "print(f\"LSTM - Loss: {lstm_loss_20:.4f}, Accuracy: {lstm_acc_20:.2f}%, Time: {lstm_time_20:.2f} seconds\")\n",
    "print(f\"GRU  - Loss: {gru_loss_20:.4f}, Accuracy: {gru_acc_20:.2f}%, Time: {gru_time_20:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model for sequence length 30...\n",
      "Epoch [1/10], Loss: 1.9121\n",
      "Epoch [2/10], Loss: 2.4615\n",
      "Epoch [3/10], Loss: 1.8835\n",
      "Epoch [4/10], Loss: 1.5444\n",
      "Epoch [5/10], Loss: 1.0117\n",
      "Epoch [6/10], Loss: 0.8037\n",
      "Epoch [7/10], Loss: 0.4261\n",
      "Epoch [8/10], Loss: 1.0790\n",
      "Epoch [9/10], Loss: 0.4648\n",
      "Epoch [10/10], Loss: 1.8897\n",
      "Training GRU model for sequence length 30...\n",
      "Epoch [1/10], Loss: 1.0423\n",
      "Epoch [2/10], Loss: 1.5016\n",
      "Epoch [3/10], Loss: 0.6718\n",
      "Epoch [4/10], Loss: 1.6727\n",
      "Epoch [5/10], Loss: 1.0290\n",
      "Epoch [6/10], Loss: 2.7371\n",
      "Epoch [7/10], Loss: 1.6883\n",
      "Epoch [8/10], Loss: 1.0107\n",
      "Epoch [9/10], Loss: 0.6896\n",
      "Epoch [10/10], Loss: 0.5744\n",
      "\n",
      "Comparison for Sequence Length 30:\n",
      "LSTM - Loss: 1.8897, Accuracy: 59.28%, Time: 312.79 seconds\n",
      "GRU  - Loss: 0.5744, Accuracy: 58.29%, Time: 293.38 seconds\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset for sequence length 30\n",
    "sequence_length_30 = 30\n",
    "\n",
    "sequences_30 = []\n",
    "targets_30 = []\n",
    "for i in range(0, len(encoded_text) - sequence_length_30):\n",
    "    seq = encoded_text[i:i+sequence_length_30]\n",
    "    target = encoded_text[i+sequence_length_30]\n",
    "    sequences_30.append(seq)\n",
    "    targets_30.append(target)\n",
    "\n",
    "sequences_30 = torch.tensor(sequences_30, dtype=torch.long)\n",
    "targets_30 = torch.tensor(targets_30, dtype=torch.long)\n",
    "\n",
    "dataset_30 = CharDataset(sequences_30, targets_30)\n",
    "\n",
    "train_size_30 = int(len(dataset_30) * 0.8)\n",
    "test_size_30 = len(dataset_30) - train_size_30\n",
    "train_dataset_30, test_dataset_30 = torch.utils.data.random_split(dataset_30, [train_size_30, test_size_30])\n",
    "\n",
    "train_loader_30 = DataLoader(train_dataset_30, shuffle=True, batch_size=batch_size)\n",
    "test_loader_30 = DataLoader(test_dataset_30, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# Train LSTM and GRU models for sequence length 30\n",
    "lstm_model_30 = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "gru_model_30 = GRUModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "print(\"Training LSTM model for sequence length 30...\")\n",
    "lstm_loss_30, lstm_acc_30, lstm_time_30, _ = train_model(lstm_model_30, train_loader_30, test_loader_30, device, num_epochs, lr)\n",
    "print(\"Training GRU model for sequence length 30...\")\n",
    "gru_loss_30, gru_acc_30, gru_time_30, _ = train_model(gru_model_30, train_loader_30, test_loader_30, device, num_epochs, lr)\n",
    "\n",
    "# Compare the results for sequence length 30\n",
    "print(\"\\nComparison for Sequence Length 30:\")\n",
    "print(f\"LSTM - Loss: {lstm_loss_30:.4f}, Accuracy: {lstm_acc_30:.2f}%, Time: {lstm_time_30:.2f} seconds\")\n",
    "print(f\"GRU  - Loss: {gru_loss_30:.4f}, Accuracy: {gru_acc_30:.2f}%, Time: {gru_time_30:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM with hidden_size=128, num_layers=1, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 2.4156\n",
      "Epoch [2/10], Loss: 1.6438\n",
      "Epoch [3/10], Loss: 2.1643\n",
      "Epoch [4/10], Loss: 1.7018\n",
      "Epoch [5/10], Loss: 1.6927\n",
      "Epoch [6/10], Loss: 1.5463\n",
      "Epoch [7/10], Loss: 2.3809\n",
      "Epoch [8/10], Loss: 0.7570\n",
      "Epoch [9/10], Loss: 1.5755\n",
      "Epoch [10/10], Loss: 1.1622\n",
      "Loss: 1.1622, Accuracy: 57.88%, Time: 147.59 seconds\n",
      "\n",
      "Training LSTM with hidden_size=128, num_layers=1, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 2.2092\n",
      "Epoch [2/10], Loss: 1.2664\n",
      "Epoch [3/10], Loss: 1.1880\n",
      "Epoch [4/10], Loss: 1.7711\n",
      "Epoch [5/10], Loss: 1.0886\n",
      "Epoch [6/10], Loss: 0.6377\n",
      "Epoch [7/10], Loss: 1.5098\n",
      "Epoch [8/10], Loss: 1.3846\n",
      "Epoch [9/10], Loss: 1.4459\n",
      "Epoch [10/10], Loss: 0.8956\n",
      "Loss: 0.8956, Accuracy: 57.06%, Time: 155.47 seconds\n",
      "\n",
      "Training LSTM with hidden_size=128, num_layers=1, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 1.8636\n",
      "Epoch [2/10], Loss: 1.6921\n",
      "Epoch [3/10], Loss: 1.6708\n",
      "Epoch [4/10], Loss: 1.8119\n",
      "Epoch [5/10], Loss: 1.8178\n",
      "Epoch [6/10], Loss: 2.5198\n",
      "Epoch [7/10], Loss: 1.3176\n",
      "Epoch [8/10], Loss: 0.9794\n",
      "Epoch [9/10], Loss: 1.0607\n",
      "Epoch [10/10], Loss: 0.8966\n",
      "Loss: 0.8966, Accuracy: 57.46%, Time: 163.76 seconds\n",
      "\n",
      "Training LSTM with hidden_size=128, num_layers=2, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.1308\n",
      "Epoch [2/10], Loss: 2.9214\n",
      "Epoch [3/10], Loss: 1.5615\n",
      "Epoch [4/10], Loss: 1.4518\n",
      "Epoch [5/10], Loss: 1.7149\n",
      "Epoch [6/10], Loss: 1.2771\n",
      "Epoch [7/10], Loss: 1.9298\n",
      "Epoch [8/10], Loss: 2.1596\n",
      "Epoch [9/10], Loss: 0.4280\n",
      "Epoch [10/10], Loss: 1.2649\n",
      "Loss: 1.2649, Accuracy: 58.29%, Time: 151.52 seconds\n",
      "\n",
      "Training LSTM with hidden_size=128, num_layers=2, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 2.4640\n",
      "Epoch [2/10], Loss: 0.8845\n",
      "Epoch [3/10], Loss: 1.7380\n",
      "Epoch [4/10], Loss: 1.5026\n",
      "Epoch [5/10], Loss: 0.6834\n",
      "Epoch [6/10], Loss: 0.9668\n",
      "Epoch [7/10], Loss: 1.1903\n",
      "Epoch [8/10], Loss: 1.1688\n",
      "Epoch [9/10], Loss: 1.5649\n",
      "Epoch [10/10], Loss: 1.8613\n",
      "Loss: 1.8613, Accuracy: 57.62%, Time: 167.99 seconds\n",
      "\n",
      "Training LSTM with hidden_size=128, num_layers=2, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 1.3853\n",
      "Epoch [2/10], Loss: 3.0061\n",
      "Epoch [3/10], Loss: 1.9620\n",
      "Epoch [4/10], Loss: 1.0495\n",
      "Epoch [5/10], Loss: 2.8063\n",
      "Epoch [6/10], Loss: 1.3528\n",
      "Epoch [7/10], Loss: 2.0349\n",
      "Epoch [8/10], Loss: 2.1201\n",
      "Epoch [9/10], Loss: 1.1169\n",
      "Epoch [10/10], Loss: 1.3960\n",
      "Loss: 1.3960, Accuracy: 57.65%, Time: 176.58 seconds\n",
      "\n",
      "Training LSTM with hidden_size=128, num_layers=3, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.6701\n",
      "Epoch [2/10], Loss: 1.4990\n",
      "Epoch [3/10], Loss: 1.0910\n",
      "Epoch [4/10], Loss: 1.2653\n",
      "Epoch [5/10], Loss: 1.5828\n",
      "Epoch [6/10], Loss: 2.1916\n",
      "Epoch [7/10], Loss: 0.9027\n",
      "Epoch [8/10], Loss: 0.9646\n",
      "Epoch [9/10], Loss: 1.7337\n",
      "Epoch [10/10], Loss: 0.7810\n",
      "Loss: 0.7810, Accuracy: 58.28%, Time: 167.35 seconds\n",
      "\n",
      "Training LSTM with hidden_size=128, num_layers=3, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 1.8360\n",
      "Epoch [2/10], Loss: 1.6973\n",
      "Epoch [3/10], Loss: 1.2086\n",
      "Epoch [4/10], Loss: 2.1573\n",
      "Epoch [5/10], Loss: 2.3577\n",
      "Epoch [6/10], Loss: 1.5799\n",
      "Epoch [7/10], Loss: 1.6196\n",
      "Epoch [8/10], Loss: 0.8767\n",
      "Epoch [9/10], Loss: 0.6295\n",
      "Epoch [10/10], Loss: 1.6239\n",
      "Loss: 1.6239, Accuracy: 56.58%, Time: 174.45 seconds\n",
      "\n",
      "Training LSTM with hidden_size=128, num_layers=3, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 1.8707\n",
      "Epoch [2/10], Loss: 1.3817\n",
      "Epoch [3/10], Loss: 1.1076\n",
      "Epoch [4/10], Loss: 1.8262\n",
      "Epoch [5/10], Loss: 1.2135\n",
      "Epoch [6/10], Loss: 1.4573\n",
      "Epoch [7/10], Loss: 1.4870\n",
      "Epoch [8/10], Loss: 1.2449\n",
      "Epoch [9/10], Loss: 2.0597\n",
      "Epoch [10/10], Loss: 1.3376\n",
      "Loss: 1.3376, Accuracy: 57.88%, Time: 186.18 seconds\n",
      "\n",
      "Training LSTM with hidden_size=256, num_layers=1, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 2.3655\n",
      "Epoch [2/10], Loss: 0.7892\n",
      "Epoch [3/10], Loss: 1.3995\n",
      "Epoch [4/10], Loss: 1.8025\n",
      "Epoch [5/10], Loss: 0.6890\n",
      "Epoch [6/10], Loss: 1.3231\n",
      "Epoch [7/10], Loss: 0.8906\n",
      "Epoch [8/10], Loss: 1.1837\n",
      "Epoch [9/10], Loss: 1.2590\n",
      "Epoch [10/10], Loss: 1.2270\n",
      "Loss: 1.2270, Accuracy: 58.92%, Time: 196.74 seconds\n",
      "\n",
      "Training LSTM with hidden_size=256, num_layers=1, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 1.6314\n",
      "Epoch [2/10], Loss: 1.7626\n",
      "Epoch [3/10], Loss: 1.6825\n",
      "Epoch [4/10], Loss: 1.1024\n",
      "Epoch [5/10], Loss: 1.6199\n",
      "Epoch [6/10], Loss: 1.0727\n",
      "Epoch [7/10], Loss: 1.5016\n",
      "Epoch [8/10], Loss: 1.8486\n",
      "Epoch [9/10], Loss: 1.1502\n",
      "Epoch [10/10], Loss: 1.3798\n",
      "Loss: 1.3798, Accuracy: 58.54%, Time: 207.90 seconds\n",
      "\n",
      "Training LSTM with hidden_size=256, num_layers=1, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 2.4261\n",
      "Epoch [2/10], Loss: 1.8321\n",
      "Epoch [3/10], Loss: 0.5346\n",
      "Epoch [4/10], Loss: 1.0306\n",
      "Epoch [5/10], Loss: 1.2415\n",
      "Epoch [6/10], Loss: 1.1348\n",
      "Epoch [7/10], Loss: 0.9222\n",
      "Epoch [8/10], Loss: 0.9890\n",
      "Epoch [9/10], Loss: 1.2833\n",
      "Epoch [10/10], Loss: 1.2965\n",
      "Loss: 1.2965, Accuracy: 58.40%, Time: 216.54 seconds\n",
      "\n",
      "Training LSTM with hidden_size=256, num_layers=2, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 2.1909\n",
      "Epoch [2/10], Loss: 1.1405\n",
      "Epoch [3/10], Loss: 0.9911\n",
      "Epoch [4/10], Loss: 0.5652\n",
      "Epoch [5/10], Loss: 1.0255\n",
      "Epoch [6/10], Loss: 0.9991\n",
      "Epoch [7/10], Loss: 1.2085\n",
      "Epoch [8/10], Loss: 2.1539\n",
      "Epoch [9/10], Loss: 1.1012\n",
      "Epoch [10/10], Loss: 1.1160\n",
      "Loss: 1.1160, Accuracy: 59.07%, Time: 265.30 seconds\n",
      "\n",
      "Training LSTM with hidden_size=256, num_layers=2, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 2.1986\n",
      "Epoch [2/10], Loss: 2.1264\n",
      "Epoch [3/10], Loss: 1.9022\n",
      "Epoch [4/10], Loss: 1.8151\n",
      "Epoch [5/10], Loss: 1.2547\n",
      "Epoch [6/10], Loss: 1.1693\n",
      "Epoch [7/10], Loss: 2.0996\n",
      "Epoch [8/10], Loss: 1.6963\n",
      "Epoch [9/10], Loss: 1.1327\n",
      "Epoch [10/10], Loss: 1.4388\n",
      "Loss: 1.4388, Accuracy: 58.20%, Time: 279.87 seconds\n",
      "\n",
      "Training LSTM with hidden_size=256, num_layers=2, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 2.0302\n",
      "Epoch [2/10], Loss: 1.7495\n",
      "Epoch [3/10], Loss: 2.1571\n",
      "Epoch [4/10], Loss: 1.2583\n",
      "Epoch [5/10], Loss: 1.4808\n",
      "Epoch [6/10], Loss: 0.9195\n",
      "Epoch [7/10], Loss: 1.6177\n",
      "Epoch [8/10], Loss: 0.8911\n",
      "Epoch [9/10], Loss: 1.4536\n",
      "Epoch [10/10], Loss: 1.2201\n",
      "Loss: 1.2201, Accuracy: 58.37%, Time: 284.40 seconds\n",
      "\n",
      "Training LSTM with hidden_size=256, num_layers=3, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.6671\n",
      "Epoch [2/10], Loss: 0.4292\n",
      "Epoch [3/10], Loss: 1.7184\n",
      "Epoch [4/10], Loss: 2.3883\n",
      "Epoch [5/10], Loss: 1.5564\n",
      "Epoch [6/10], Loss: 0.9359\n",
      "Epoch [7/10], Loss: 1.6980\n",
      "Epoch [8/10], Loss: 0.8167\n",
      "Epoch [9/10], Loss: 1.2542\n",
      "Epoch [10/10], Loss: 1.3909\n",
      "Loss: 1.3909, Accuracy: 56.15%, Time: 323.46 seconds\n",
      "\n",
      "Training LSTM with hidden_size=256, num_layers=3, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 2.2143\n",
      "Epoch [2/10], Loss: 1.1459\n",
      "Epoch [3/10], Loss: 0.9527\n",
      "Epoch [4/10], Loss: 1.4461\n",
      "Epoch [5/10], Loss: 1.4196\n",
      "Epoch [6/10], Loss: 1.6895\n",
      "Epoch [7/10], Loss: 1.6067\n",
      "Epoch [8/10], Loss: 1.6010\n",
      "Epoch [9/10], Loss: 1.5729\n",
      "Epoch [10/10], Loss: 1.3971\n",
      "Loss: 1.3971, Accuracy: 58.45%, Time: 329.85 seconds\n",
      "\n",
      "Training LSTM with hidden_size=256, num_layers=3, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 1.5224\n",
      "Epoch [2/10], Loss: 1.5386\n",
      "Epoch [3/10], Loss: 1.9429\n",
      "Epoch [4/10], Loss: 0.7416\n",
      "Epoch [5/10], Loss: 1.2020\n",
      "Epoch [6/10], Loss: 2.2306\n",
      "Epoch [7/10], Loss: 2.4372\n",
      "Epoch [8/10], Loss: 1.3256\n",
      "Epoch [9/10], Loss: 1.1137\n",
      "Epoch [10/10], Loss: 0.9281\n",
      "Loss: 0.9281, Accuracy: 58.30%, Time: 343.85 seconds\n",
      "\n",
      "Training LSTM with hidden_size=512, num_layers=1, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.5767\n",
      "Epoch [2/10], Loss: 1.2191\n",
      "Epoch [3/10], Loss: 2.3960\n",
      "Epoch [4/10], Loss: 0.4894\n",
      "Epoch [5/10], Loss: 1.4567\n",
      "Epoch [6/10], Loss: 1.3413\n",
      "Epoch [7/10], Loss: 1.7296\n",
      "Epoch [8/10], Loss: 1.8223\n",
      "Epoch [9/10], Loss: 0.8291\n",
      "Epoch [10/10], Loss: 0.9471\n",
      "Loss: 0.9471, Accuracy: 59.04%, Time: 195.18 seconds\n",
      "\n",
      "Training LSTM with hidden_size=512, num_layers=1, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 1.0686\n",
      "Epoch [2/10], Loss: 1.5495\n",
      "Epoch [3/10], Loss: 0.6618\n",
      "Epoch [4/10], Loss: 1.7448\n",
      "Epoch [5/10], Loss: 1.1038\n",
      "Epoch [6/10], Loss: 0.9276\n",
      "Epoch [7/10], Loss: 1.4643\n",
      "Epoch [8/10], Loss: 1.3396\n",
      "Epoch [9/10], Loss: 0.9579\n",
      "Epoch [10/10], Loss: 1.0107\n",
      "Loss: 1.0107, Accuracy: 59.00%, Time: 201.36 seconds\n",
      "\n",
      "Training LSTM with hidden_size=512, num_layers=1, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 1.2805\n",
      "Epoch [2/10], Loss: 1.3754\n",
      "Epoch [3/10], Loss: 1.0842\n",
      "Epoch [4/10], Loss: 0.5585\n",
      "Epoch [5/10], Loss: 1.3811\n",
      "Epoch [6/10], Loss: 1.7576\n",
      "Epoch [7/10], Loss: 0.7752\n",
      "Epoch [8/10], Loss: 1.0003\n",
      "Epoch [9/10], Loss: 1.3302\n",
      "Epoch [10/10], Loss: 1.3785\n",
      "Loss: 1.3785, Accuracy: 59.22%, Time: 214.81 seconds\n",
      "\n",
      "Training LSTM with hidden_size=512, num_layers=2, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 2.5889\n",
      "Epoch [2/10], Loss: 1.0711\n",
      "Epoch [3/10], Loss: 1.3625\n",
      "Epoch [4/10], Loss: 1.2098\n",
      "Epoch [5/10], Loss: 1.7081\n",
      "Epoch [6/10], Loss: 0.9715\n",
      "Epoch [7/10], Loss: 0.7673\n",
      "Epoch [8/10], Loss: 1.1210\n",
      "Epoch [9/10], Loss: 1.2395\n",
      "Epoch [10/10], Loss: 1.2714\n",
      "Loss: 1.2714, Accuracy: 58.99%, Time: 302.95 seconds\n",
      "\n",
      "Training LSTM with hidden_size=512, num_layers=2, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 1.3448\n",
      "Epoch [2/10], Loss: 1.3125\n",
      "Epoch [3/10], Loss: 1.6217\n",
      "Epoch [4/10], Loss: 1.4249\n",
      "Epoch [5/10], Loss: 1.1159\n",
      "Epoch [6/10], Loss: 1.2819\n",
      "Epoch [7/10], Loss: 1.9886\n",
      "Epoch [8/10], Loss: 0.7040\n",
      "Epoch [9/10], Loss: 0.6338\n",
      "Epoch [10/10], Loss: 1.0660\n",
      "Loss: 1.0660, Accuracy: 58.85%, Time: 314.60 seconds\n",
      "\n",
      "Training LSTM with hidden_size=512, num_layers=2, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 1.7964\n",
      "Epoch [2/10], Loss: 2.3319\n",
      "Epoch [3/10], Loss: 1.1466\n",
      "Epoch [4/10], Loss: 1.8486\n",
      "Epoch [5/10], Loss: 1.4807\n",
      "Epoch [6/10], Loss: 2.3880\n",
      "Epoch [7/10], Loss: 1.6501\n",
      "Epoch [8/10], Loss: 1.9960\n",
      "Epoch [9/10], Loss: 1.3755\n",
      "Epoch [10/10], Loss: 1.4808\n",
      "Loss: 1.4808, Accuracy: 58.89%, Time: 322.36 seconds\n",
      "\n",
      "Training LSTM with hidden_size=512, num_layers=3, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.2287\n",
      "Epoch [2/10], Loss: 0.8520\n",
      "Epoch [3/10], Loss: 1.4521\n",
      "Epoch [4/10], Loss: 1.5704\n",
      "Epoch [5/10], Loss: 0.5420\n",
      "Epoch [6/10], Loss: 0.5971\n",
      "Epoch [7/10], Loss: 1.5791\n",
      "Epoch [8/10], Loss: 2.1839\n",
      "Epoch [9/10], Loss: 1.8396\n",
      "Epoch [10/10], Loss: 1.0987\n",
      "Loss: 1.0987, Accuracy: 59.50%, Time: 407.07 seconds\n",
      "\n",
      "Training LSTM with hidden_size=512, num_layers=3, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 3.2663\n",
      "Epoch [2/10], Loss: 3.5316\n",
      "Epoch [3/10], Loss: 3.6314\n",
      "Epoch [4/10], Loss: 3.7253\n",
      "Epoch [5/10], Loss: 3.1456\n",
      "Epoch [6/10], Loss: 3.3463\n",
      "Epoch [7/10], Loss: 3.2445\n",
      "Epoch [8/10], Loss: 3.1950\n",
      "Epoch [9/10], Loss: 2.9498\n",
      "Epoch [10/10], Loss: 3.5569\n",
      "Loss: 3.5569, Accuracy: 15.16%, Time: 412.09 seconds\n",
      "\n",
      "Training LSTM with hidden_size=512, num_layers=3, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 3.3720\n",
      "Epoch [2/10], Loss: 3.2251\n",
      "Epoch [3/10], Loss: 3.4255\n",
      "Epoch [4/10], Loss: 3.2234\n",
      "Epoch [5/10], Loss: 2.8446\n",
      "Epoch [6/10], Loss: 4.1054\n",
      "Epoch [7/10], Loss: 3.4055\n",
      "Epoch [8/10], Loss: 3.3392\n",
      "Epoch [9/10], Loss: 2.7878\n",
      "Epoch [10/10], Loss: 3.2572\n",
      "Loss: 3.2572, Accuracy: 15.16%, Time: 426.50 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#b\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, fc_layers):\n",
    "        super(CustomLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for i in range(len(fc_layers)):\n",
    "            if i == 0:\n",
    "                self.fc_layers.append(nn.Linear(hidden_size, fc_layers[i]))\n",
    "            else:\n",
    "                self.fc_layers.append(nn.Linear(fc_layers[i-1], fc_layers[i]))\n",
    "        self.final_fc = nn.Linear(fc_layers[-1], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        for fc_layer in self.fc_layers:\n",
    "            out = F.relu(fc_layer(out))\n",
    "        \n",
    "        out = self.final_fc(out)\n",
    "        return out\n",
    "\n",
    "# Experiment with different hyperparameters\n",
    "hidden_sizes = [128, 256, 512]\n",
    "num_layers = [1, 2, 3]\n",
    "fc_structures = [[256], [128, 64], [256, 128, 64]]\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    for num_layer in num_layers:\n",
    "        for fc_structure in fc_structures:\n",
    "            print(f\"Training LSTM with hidden_size={hidden_size}, num_layers={num_layer}, fc_structure={fc_structure}...\")\n",
    "            model = CustomLSTMModel(input_size, hidden_size, num_layer, output_size, fc_structure)\n",
    "            train_loss, val_acc, train_time, _ = train_model(model, train_loader, test_loader, device, num_epochs, lr)\n",
    "            print(f\"Loss: {train_loss:.4f}, Accuracy: {val_acc:.2f}%, Time: {train_time:.2f} seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GRU with hidden_size=128, num_layers=1, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.9982\n",
      "Epoch [2/10], Loss: 1.9370\n",
      "Epoch [3/10], Loss: 1.5548\n",
      "Epoch [4/10], Loss: 1.3857\n",
      "Epoch [5/10], Loss: 1.0671\n",
      "Epoch [6/10], Loss: 1.9775\n",
      "Epoch [7/10], Loss: 1.6671\n",
      "Epoch [8/10], Loss: 0.5999\n",
      "Epoch [9/10], Loss: 0.5057\n",
      "Epoch [10/10], Loss: 1.0725\n",
      "Loss: 1.0725, Accuracy: 57.49%, Time: 146.27 seconds\n",
      "\n",
      "Training GRU with hidden_size=128, num_layers=1, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 1.3715\n",
      "Epoch [2/10], Loss: 1.9282\n",
      "Epoch [3/10], Loss: 1.0398\n",
      "Epoch [4/10], Loss: 0.9333\n",
      "Epoch [5/10], Loss: 1.2576\n",
      "Epoch [6/10], Loss: 1.1297\n",
      "Epoch [7/10], Loss: 1.7954\n",
      "Epoch [8/10], Loss: 1.5984\n",
      "Epoch [9/10], Loss: 1.3637\n",
      "Epoch [10/10], Loss: 1.4769\n",
      "Loss: 1.4769, Accuracy: 56.73%, Time: 160.99 seconds\n",
      "\n",
      "Training GRU with hidden_size=128, num_layers=1, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 2.1779\n",
      "Epoch [2/10], Loss: 2.0746\n",
      "Epoch [3/10], Loss: 1.5493\n",
      "Epoch [4/10], Loss: 1.7353\n",
      "Epoch [5/10], Loss: 1.0198\n",
      "Epoch [6/10], Loss: 1.6909\n",
      "Epoch [7/10], Loss: 0.9853\n",
      "Epoch [8/10], Loss: 1.7459\n",
      "Epoch [9/10], Loss: 0.8655\n",
      "Epoch [10/10], Loss: 1.7033\n",
      "Loss: 1.7033, Accuracy: 57.20%, Time: 164.96 seconds\n",
      "\n",
      "Training GRU with hidden_size=128, num_layers=2, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.3618\n",
      "Epoch [2/10], Loss: 1.6698\n",
      "Epoch [3/10], Loss: 1.0826\n",
      "Epoch [4/10], Loss: 1.6731\n",
      "Epoch [5/10], Loss: 1.1303\n",
      "Epoch [6/10], Loss: 2.2479\n",
      "Epoch [7/10], Loss: 1.5460\n",
      "Epoch [8/10], Loss: 0.7701\n",
      "Epoch [9/10], Loss: 0.7002\n",
      "Epoch [10/10], Loss: 2.1677\n",
      "Loss: 2.1677, Accuracy: 57.83%, Time: 153.40 seconds\n",
      "\n",
      "Training GRU with hidden_size=128, num_layers=2, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 1.5976\n",
      "Epoch [2/10], Loss: 2.7749\n",
      "Epoch [3/10], Loss: 2.4814\n",
      "Epoch [4/10], Loss: 1.8103\n",
      "Epoch [5/10], Loss: 1.3078\n",
      "Epoch [6/10], Loss: 0.7106\n",
      "Epoch [7/10], Loss: 2.7153\n",
      "Epoch [8/10], Loss: 1.7191\n",
      "Epoch [9/10], Loss: 1.9804\n",
      "Epoch [10/10], Loss: 1.9446\n",
      "Loss: 1.9446, Accuracy: 57.29%, Time: 166.22 seconds\n",
      "\n",
      "Training GRU with hidden_size=128, num_layers=2, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 1.5563\n",
      "Epoch [2/10], Loss: 1.8463\n",
      "Epoch [3/10], Loss: 1.3453\n",
      "Epoch [4/10], Loss: 2.8037\n",
      "Epoch [5/10], Loss: 1.1773\n",
      "Epoch [6/10], Loss: 1.3820\n",
      "Epoch [7/10], Loss: 1.6085\n",
      "Epoch [8/10], Loss: 1.7106\n",
      "Epoch [9/10], Loss: 1.8825\n",
      "Epoch [10/10], Loss: 1.0932\n",
      "Loss: 1.0932, Accuracy: 57.17%, Time: 174.93 seconds\n",
      "\n",
      "Training GRU with hidden_size=128, num_layers=3, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.7520\n",
      "Epoch [2/10], Loss: 1.8475\n",
      "Epoch [3/10], Loss: 1.6844\n",
      "Epoch [4/10], Loss: 2.0327\n",
      "Epoch [5/10], Loss: 1.2975\n",
      "Epoch [6/10], Loss: 1.0869\n",
      "Epoch [7/10], Loss: 1.2645\n",
      "Epoch [8/10], Loss: 0.7716\n",
      "Epoch [9/10], Loss: 1.0392\n",
      "Epoch [10/10], Loss: 1.3163\n",
      "Loss: 1.3163, Accuracy: 57.41%, Time: 168.11 seconds\n",
      "\n",
      "Training GRU with hidden_size=128, num_layers=3, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 0.9985\n",
      "Epoch [2/10], Loss: 1.7131\n",
      "Epoch [3/10], Loss: 1.5133\n",
      "Epoch [4/10], Loss: 1.3113\n",
      "Epoch [5/10], Loss: 0.7695\n",
      "Epoch [6/10], Loss: 0.9859\n",
      "Epoch [7/10], Loss: 1.0791\n",
      "Epoch [8/10], Loss: 1.4940\n",
      "Epoch [9/10], Loss: 0.9800\n",
      "Epoch [10/10], Loss: 2.1823\n",
      "Loss: 2.1823, Accuracy: 57.19%, Time: 179.26 seconds\n",
      "\n",
      "Training GRU with hidden_size=128, num_layers=3, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 1.5288\n",
      "Epoch [2/10], Loss: 2.1541\n",
      "Epoch [3/10], Loss: 1.6561\n",
      "Epoch [4/10], Loss: 1.7691\n",
      "Epoch [5/10], Loss: 1.8869\n",
      "Epoch [6/10], Loss: 2.0015\n",
      "Epoch [7/10], Loss: 1.4617\n",
      "Epoch [8/10], Loss: 1.4417\n",
      "Epoch [9/10], Loss: 1.0156\n",
      "Epoch [10/10], Loss: 1.2617\n",
      "Loss: 1.2617, Accuracy: 56.87%, Time: 184.01 seconds\n",
      "\n",
      "Training GRU with hidden_size=256, num_layers=1, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.1809\n",
      "Epoch [2/10], Loss: 1.6774\n",
      "Epoch [3/10], Loss: 0.3631\n",
      "Epoch [4/10], Loss: 1.2258\n",
      "Epoch [5/10], Loss: 1.4013\n",
      "Epoch [6/10], Loss: 1.7487\n",
      "Epoch [7/10], Loss: 1.3408\n",
      "Epoch [8/10], Loss: 0.7479\n",
      "Epoch [9/10], Loss: 1.3029\n",
      "Epoch [10/10], Loss: 1.7993\n",
      "Loss: 1.7993, Accuracy: 58.59%, Time: 194.31 seconds\n",
      "\n",
      "Training GRU with hidden_size=256, num_layers=1, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 1.3786\n",
      "Epoch [2/10], Loss: 1.3066\n",
      "Epoch [3/10], Loss: 2.2593\n",
      "Epoch [4/10], Loss: 0.6176\n",
      "Epoch [5/10], Loss: 1.8540\n",
      "Epoch [6/10], Loss: 1.4412\n",
      "Epoch [7/10], Loss: 0.4626\n",
      "Epoch [8/10], Loss: 0.9482\n",
      "Epoch [9/10], Loss: 1.8221\n",
      "Epoch [10/10], Loss: 0.3115\n",
      "Loss: 0.3115, Accuracy: 58.17%, Time: 199.63 seconds\n",
      "\n",
      "Training GRU with hidden_size=256, num_layers=1, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 1.4045\n",
      "Epoch [2/10], Loss: 0.8223\n",
      "Epoch [3/10], Loss: 1.2701\n",
      "Epoch [4/10], Loss: 1.2866\n",
      "Epoch [5/10], Loss: 1.2188\n",
      "Epoch [6/10], Loss: 1.9435\n",
      "Epoch [7/10], Loss: 1.3012\n",
      "Epoch [8/10], Loss: 1.1068\n",
      "Epoch [9/10], Loss: 1.4828\n",
      "Epoch [10/10], Loss: 1.4410\n",
      "Loss: 1.4410, Accuracy: 57.97%, Time: 210.02 seconds\n",
      "\n",
      "Training GRU with hidden_size=256, num_layers=2, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.5779\n",
      "Epoch [2/10], Loss: 1.1923\n",
      "Epoch [3/10], Loss: 1.1122\n",
      "Epoch [4/10], Loss: 2.0789\n",
      "Epoch [5/10], Loss: 1.4163\n",
      "Epoch [6/10], Loss: 1.6703\n",
      "Epoch [7/10], Loss: 1.5725\n",
      "Epoch [8/10], Loss: 0.7417\n",
      "Epoch [9/10], Loss: 0.9271\n",
      "Epoch [10/10], Loss: 2.5281\n",
      "Loss: 2.5281, Accuracy: 57.84%, Time: 252.80 seconds\n",
      "\n",
      "Training GRU with hidden_size=256, num_layers=2, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 1.0320\n",
      "Epoch [2/10], Loss: 1.5736\n",
      "Epoch [3/10], Loss: 0.9955\n",
      "Epoch [4/10], Loss: 0.9617\n",
      "Epoch [5/10], Loss: 0.9910\n",
      "Epoch [6/10], Loss: 1.3633\n",
      "Epoch [7/10], Loss: 1.7099\n",
      "Epoch [8/10], Loss: 1.5565\n",
      "Epoch [9/10], Loss: 0.8402\n",
      "Epoch [10/10], Loss: 1.5058\n",
      "Loss: 1.5058, Accuracy: 57.98%, Time: 267.96 seconds\n",
      "\n",
      "Training GRU with hidden_size=256, num_layers=2, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 2.0551\n",
      "Epoch [2/10], Loss: 1.6538\n",
      "Epoch [3/10], Loss: 1.1266\n",
      "Epoch [4/10], Loss: 1.9115\n",
      "Epoch [5/10], Loss: 1.0467\n",
      "Epoch [6/10], Loss: 1.4763\n",
      "Epoch [7/10], Loss: 1.1909\n",
      "Epoch [8/10], Loss: 1.7195\n",
      "Epoch [9/10], Loss: 1.9416\n",
      "Epoch [10/10], Loss: 1.1802\n",
      "Loss: 1.1802, Accuracy: 58.01%, Time: 273.65 seconds\n",
      "\n",
      "Training GRU with hidden_size=256, num_layers=3, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.2295\n",
      "Epoch [2/10], Loss: 1.8308\n",
      "Epoch [3/10], Loss: 1.5091\n",
      "Epoch [4/10], Loss: 1.2672\n",
      "Epoch [5/10], Loss: 1.3863\n",
      "Epoch [6/10], Loss: 1.9136\n",
      "Epoch [7/10], Loss: 1.6358\n",
      "Epoch [8/10], Loss: 0.7648\n",
      "Epoch [9/10], Loss: 1.7691\n",
      "Epoch [10/10], Loss: 1.0852\n",
      "Loss: 1.0852, Accuracy: 57.01%, Time: 311.12 seconds\n",
      "\n",
      "Training GRU with hidden_size=256, num_layers=3, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 1.4157\n",
      "Epoch [2/10], Loss: 1.9438\n",
      "Epoch [3/10], Loss: 1.3355\n",
      "Epoch [4/10], Loss: 1.4792\n",
      "Epoch [5/10], Loss: 1.1703\n",
      "Epoch [6/10], Loss: 0.8452\n",
      "Epoch [7/10], Loss: 0.9312\n",
      "Epoch [8/10], Loss: 0.8699\n",
      "Epoch [9/10], Loss: 1.3984\n",
      "Epoch [10/10], Loss: 0.8138\n",
      "Loss: 0.8138, Accuracy: 57.23%, Time: 322.13 seconds\n",
      "\n",
      "Training GRU with hidden_size=256, num_layers=3, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 1.8398\n",
      "Epoch [2/10], Loss: 1.9063\n",
      "Epoch [3/10], Loss: 1.4474\n",
      "Epoch [4/10], Loss: 2.0546\n",
      "Epoch [5/10], Loss: 1.8305\n",
      "Epoch [6/10], Loss: 1.5256\n",
      "Epoch [7/10], Loss: 1.6160\n",
      "Epoch [8/10], Loss: 1.4443\n",
      "Epoch [9/10], Loss: 1.5817\n",
      "Epoch [10/10], Loss: 1.7420\n",
      "Loss: 1.7420, Accuracy: 53.26%, Time: 331.95 seconds\n",
      "\n",
      "Training GRU with hidden_size=512, num_layers=1, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.8422\n",
      "Epoch [2/10], Loss: 1.7339\n",
      "Epoch [3/10], Loss: 1.3252\n",
      "Epoch [4/10], Loss: 1.1889\n",
      "Epoch [5/10], Loss: 0.8405\n",
      "Epoch [6/10], Loss: 1.3017\n",
      "Epoch [7/10], Loss: 0.6433\n",
      "Epoch [8/10], Loss: 1.1754\n",
      "Epoch [9/10], Loss: 0.5669\n",
      "Epoch [10/10], Loss: 1.6506\n",
      "Loss: 1.6506, Accuracy: 58.48%, Time: 198.47 seconds\n",
      "\n",
      "Training GRU with hidden_size=512, num_layers=1, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 1.6503\n",
      "Epoch [2/10], Loss: 2.0398\n",
      "Epoch [3/10], Loss: 2.3350\n",
      "Epoch [4/10], Loss: 1.5551\n",
      "Epoch [5/10], Loss: 1.1115\n",
      "Epoch [6/10], Loss: 1.3952\n",
      "Epoch [7/10], Loss: 1.3619\n",
      "Epoch [8/10], Loss: 1.2518\n",
      "Epoch [9/10], Loss: 1.1977\n",
      "Epoch [10/10], Loss: 2.2371\n",
      "Loss: 2.2371, Accuracy: 56.45%, Time: 212.24 seconds\n",
      "\n",
      "Training GRU with hidden_size=512, num_layers=1, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 2.0929\n",
      "Epoch [2/10], Loss: 2.0642\n",
      "Epoch [3/10], Loss: 1.6079\n",
      "Epoch [4/10], Loss: 1.5693\n",
      "Epoch [5/10], Loss: 0.8078\n",
      "Epoch [6/10], Loss: 1.2960\n",
      "Epoch [7/10], Loss: 1.3823\n",
      "Epoch [8/10], Loss: 1.4252\n",
      "Epoch [9/10], Loss: 1.5328\n",
      "Epoch [10/10], Loss: 1.0483\n",
      "Loss: 1.0483, Accuracy: 56.58%, Time: 220.91 seconds\n",
      "\n",
      "Training GRU with hidden_size=512, num_layers=2, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.5033\n",
      "Epoch [2/10], Loss: 1.5492\n",
      "Epoch [3/10], Loss: 0.9878\n",
      "Epoch [4/10], Loss: 1.3072\n",
      "Epoch [5/10], Loss: 1.5494\n",
      "Epoch [6/10], Loss: 2.2252\n",
      "Epoch [7/10], Loss: 1.5643\n",
      "Epoch [8/10], Loss: 1.6478\n",
      "Epoch [9/10], Loss: 0.9608\n",
      "Epoch [10/10], Loss: 0.9916\n",
      "Loss: 0.9916, Accuracy: 56.79%, Time: 276.66 seconds\n",
      "\n",
      "Training GRU with hidden_size=512, num_layers=2, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 3.6868\n",
      "Epoch [2/10], Loss: 2.2378\n",
      "Epoch [3/10], Loss: 1.3398\n",
      "Epoch [4/10], Loss: 1.5673\n",
      "Epoch [5/10], Loss: 1.9316\n",
      "Epoch [6/10], Loss: 0.7763\n",
      "Epoch [7/10], Loss: 1.3462\n",
      "Epoch [8/10], Loss: 1.2357\n",
      "Epoch [9/10], Loss: 1.0324\n",
      "Epoch [10/10], Loss: 1.2959\n",
      "Loss: 1.2959, Accuracy: 55.17%, Time: 283.53 seconds\n",
      "\n",
      "Training GRU with hidden_size=512, num_layers=2, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 2.2639\n",
      "Epoch [2/10], Loss: 1.8796\n",
      "Epoch [3/10], Loss: 1.5883\n",
      "Epoch [4/10], Loss: 2.4547\n",
      "Epoch [5/10], Loss: 2.1443\n",
      "Epoch [6/10], Loss: 1.6570\n",
      "Epoch [7/10], Loss: 1.8905\n",
      "Epoch [8/10], Loss: 1.9004\n",
      "Epoch [9/10], Loss: 1.7305\n",
      "Epoch [10/10], Loss: 1.7683\n",
      "Loss: 1.7683, Accuracy: 48.65%, Time: 290.02 seconds\n",
      "\n",
      "Training GRU with hidden_size=512, num_layers=3, fc_structure=[256]...\n",
      "Epoch [1/10], Loss: 1.4178\n",
      "Epoch [2/10], Loss: 0.8260\n",
      "Epoch [3/10], Loss: 1.9109\n",
      "Epoch [4/10], Loss: 1.5592\n",
      "Epoch [5/10], Loss: 0.6744\n",
      "Epoch [6/10], Loss: 1.4728\n",
      "Epoch [7/10], Loss: 1.0553\n",
      "Epoch [8/10], Loss: 0.9011\n",
      "Epoch [9/10], Loss: 1.0444\n",
      "Epoch [10/10], Loss: 1.1417\n",
      "Loss: 1.1417, Accuracy: 57.00%, Time: 361.62 seconds\n",
      "\n",
      "Training GRU with hidden_size=512, num_layers=3, fc_structure=[128, 64]...\n",
      "Epoch [1/10], Loss: 2.8874\n",
      "Epoch [2/10], Loss: 2.4813\n",
      "Epoch [3/10], Loss: 2.0500\n",
      "Epoch [4/10], Loss: 2.5841\n",
      "Epoch [5/10], Loss: 2.6762\n",
      "Epoch [6/10], Loss: 1.6237\n",
      "Epoch [7/10], Loss: 2.1825\n",
      "Epoch [8/10], Loss: 1.6780\n",
      "Epoch [9/10], Loss: 1.9996\n",
      "Epoch [10/10], Loss: 1.5599\n",
      "Loss: 1.5599, Accuracy: 41.49%, Time: 377.99 seconds\n",
      "\n",
      "Training GRU with hidden_size=512, num_layers=3, fc_structure=[256, 128, 64]...\n",
      "Epoch [1/10], Loss: 3.2411\n",
      "Epoch [2/10], Loss: 2.0631\n",
      "Epoch [3/10], Loss: 1.9003\n",
      "Epoch [4/10], Loss: 2.9120\n",
      "Epoch [5/10], Loss: 2.0607\n",
      "Epoch [6/10], Loss: 2.3358\n",
      "Epoch [7/10], Loss: 2.7484\n",
      "Epoch [8/10], Loss: 1.4349\n",
      "Epoch [9/10], Loss: 1.8753\n",
      "Epoch [10/10], Loss: 2.0275\n",
      "Loss: 2.0275, Accuracy: 47.74%, Time: 379.03 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class CustomGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, fc_layers):\n",
    "        super(CustomGRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for i in range(len(fc_layers)):\n",
    "            if i == 0:\n",
    "                self.fc_layers.append(nn.Linear(hidden_size, fc_layers[i]))\n",
    "            else:\n",
    "                self.fc_layers.append(nn.Linear(fc_layers[i-1], fc_layers[i]))\n",
    "        self.final_fc = nn.Linear(fc_layers[-1], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        for fc_layer in self.fc_layers:\n",
    "            out = F.relu(fc_layer(out))\n",
    "        \n",
    "        out = self.final_fc(out)\n",
    "        return out\n",
    "\n",
    "# Experiment with different hyperparameters for GRU\n",
    "for hidden_size in hidden_sizes:\n",
    "    for num_layer in num_layers:\n",
    "        for fc_structure in fc_structures:\n",
    "            print(f\"Training GRU with hidden_size={hidden_size}, num_layers={num_layer}, fc_structure={fc_structure}...\")\n",
    "            model = CustomGRUModel(input_size, hidden_size, num_layer, output_size, fc_structure)\n",
    "            train_loss, val_acc, train_time, _ = train_model(model, train_loader, test_loader, device, num_epochs, lr)\n",
    "            print(f\"Loss: {train_loss:.4f}, Accuracy: {val_acc:.2f}%, Time: {train_time:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c\n",
    "sequence_length_50 = 50\n",
    "\n",
    "sequences_50 = []\n",
    "targets_50 = []\n",
    "for i in range(0, len(encoded_text) - sequence_length_50):\n",
    "    seq = encoded_text[i:i+sequence_length_50]\n",
    "    target = encoded_text[i+sequence_length_50]\n",
    "    sequences_50.append(seq)\n",
    "    targets_50.append(target)\n",
    "\n",
    "sequences_50 = torch.tensor(sequences_50, dtype=torch.long)\n",
    "targets_50 = torch.tensor(targets_50, dtype=torch.long)\n",
    "\n",
    "dataset_50 = CharDataset(sequences_50, targets_50)\n",
    "\n",
    "train_size_50 = int(len(dataset_50) * 0.8)\n",
    "test_size_50 = len(dataset_50) - train_size_50\n",
    "train_dataset_50, test_dataset_50 = torch.utils.data.random_split(dataset_50, [train_size_50, test_size_50])\n",
    "\n",
    "train_loader_50 = DataLoader(train_dataset_50, shuffle=True, batch_size=batch_size)\n",
    "test_loader_50 = DataLoader(test_dataset_50, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM with sequence length 50, hidden_size=256, num_layers=2, fc_structure=[256, 128]...\n",
      "Epoch [1/10], Loss: 1.7243\n",
      "Epoch [2/10], Loss: 1.4626\n",
      "Epoch [3/10], Loss: 1.7132\n",
      "Epoch [4/10], Loss: 1.4565\n",
      "Epoch [5/10], Loss: 1.2884\n",
      "Epoch [6/10], Loss: 1.1689\n",
      "Epoch [7/10], Loss: 1.1518\n",
      "Epoch [8/10], Loss: 1.3237\n",
      "Epoch [9/10], Loss: 1.0500\n",
      "Epoch [10/10], Loss: 0.9918\n",
      "Loss: 0.9918, Accuracy: 59.84%, Time: 439.16 seconds\n",
      "Model Complexity (Number of Parameters): 964161\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "num_layer = 2\n",
    "fc_structure = [256, 128]\n",
    "\n",
    "print(f\"Training LSTM with sequence length 50, hidden_size={hidden_size}, num_layers={num_layer}, fc_structure={fc_structure}...\")\n",
    "model_50 = CustomLSTMModel(input_size, hidden_size, num_layer, output_size, fc_structure)\n",
    "train_loss_50, val_acc_50, train_time_50, _ = train_model(model_50, train_loader_50, test_loader_50, device, num_epochs, lr)\n",
    "print(f\"Loss: {train_loss_50:.4f}, Accuracy: {val_acc_50:.2f}%, Time: {train_time_50:.2f} seconds\")\n",
    "\n",
    "# Calculate model complexity\n",
    "num_params = sum(p.numel() for p in model_50.parameters() if p.requires_grad)\n",
    "print(f\"Model Complexity (Number of Parameters): {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GRU with sequence length 50, hidden_size=256, num_layers=2, fc_structure=[256, 128]...\n",
      "Epoch [1/10], Loss: 1.4768\n",
      "Epoch [2/10], Loss: 1.2972\n",
      "Epoch [3/10], Loss: 1.2812\n",
      "Epoch [4/10], Loss: 1.4473\n",
      "Epoch [5/10], Loss: 1.3514\n",
      "Epoch [6/10], Loss: 1.4289\n",
      "Epoch [7/10], Loss: 1.2534\n",
      "Epoch [8/10], Loss: 1.1131\n",
      "Epoch [9/10], Loss: 1.4048\n",
      "Epoch [10/10], Loss: 1.3327\n",
      "Loss: 1.3327, Accuracy: 58.79%, Time: 426.85 seconds\n",
      "Model Complexity (Number of Parameters): 749889\n"
     ]
    }
   ],
   "source": [
    "class CustomGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, fc_layers):\n",
    "        super(CustomGRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for i in range(len(fc_layers)):\n",
    "            if i == 0:\n",
    "                self.fc_layers.append(nn.Linear(hidden_size, fc_layers[i]))\n",
    "            else:\n",
    "                self.fc_layers.append(nn.Linear(fc_layers[i-1], fc_layers[i]))\n",
    "        self.final_fc = nn.Linear(fc_layers[-1], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        for fc_layer in self.fc_layers:\n",
    "            out = F.relu(fc_layer(out))\n",
    "        \n",
    "        out = self.final_fc(out)\n",
    "        return out\n",
    "\n",
    "hidden_size = 256\n",
    "num_layer = 2\n",
    "fc_structure = [256, 128]\n",
    "\n",
    "print(f\"Training GRU with sequence length 50, hidden_size={hidden_size}, num_layers={num_layer}, fc_structure={fc_structure}...\")\n",
    "model_gru_50 = CustomGRUModel(input_size, hidden_size, num_layer, output_size, fc_structure)\n",
    "train_loss_gru_50, val_acc_gru_50, train_time_gru_50, _ = train_model(model_gru_50, train_loader_50, test_loader_50, device, num_epochs, lr)\n",
    "print(f\"Loss: {train_loss_gru_50:.4f}, Accuracy: {val_acc_gru_50:.2f}%, Time: {train_time_gru_50:.2f} seconds\")\n",
    "\n",
    "# Calculate model complexity\n",
    "num_params_gru = sum(p.numel() for p in model_gru_50.parameters() if p.requires_grad)\n",
    "print(f\"Model Complexity (Number of Parameters): {num_params_gru}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
